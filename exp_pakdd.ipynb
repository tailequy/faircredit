{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import lib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from my_useful_functions import calculate_performance_statistical_parity,calculate_performance_equalized_odds,calculate_performance_equal_opportunity,calculate_performance_predictive_parity,calculate_performance_predictive_equality,calculate_performance_treatment_equality\n",
    "from sklearn import preprocessing\n",
    "from aif360.datasets.binary_label_dataset import BinaryLabelDataset\n",
    "# DT\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# NB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# kNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Agarwal\n",
    "from exponentiated_gradient_reduction import ExponentiatedGradientReduction\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# DIR\n",
    "from disparate_impact_remover import DisparateImpactRemover\n",
    "# LFR\n",
    "from learning_fair_representations import LFR\n",
    "# EOP\n",
    "from eq_odds_postprocessing import EqOddsPostprocessing\n",
    "# CEP\n",
    "from calibrated_eq_odds_postprocessing import CalibratedEqOddsPostprocessing\n",
    "from compute_abroca import *\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics \n",
    "from scipy import interpolate\n",
    "from scipy import integrate\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAKDD2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_PAKDD2010():\n",
    "    df = pd.read_csv('data/PAKDD.csv')    \n",
    "    protected_attribute = 'SEX'\n",
    "    majority_group_name = \"Male\"\n",
    "    minority_group_name = \"Female\"\n",
    "    class_label = 'TARGET_LABEL_BAD' \n",
    "    \n",
    "    print(\"Length:\",len(df))\n",
    "    print(\"Number of attribute:\",len(df.columns))\n",
    "    \n",
    "    #Remove ID\n",
    "    df=df.drop(columns=['ID_CLIENT'])\n",
    "    df =df.dropna()\n",
    "    df=df.drop(columns = ['RESIDENCIAL_PHONE_AREA_CODE','RESIDENCIAL_ZIP_3','PROFESSIONAL_ZIP_3'])\n",
    "    #Label sex\n",
    "    df['SEX']=[\"Female\" if v == \"F\" else \"Male\" for v in df['SEX']]\n",
    "    \n",
    "    \n",
    "    print(\"Length (cleaned):\",len(df))\n",
    "    print(\"Class imbalance: \\n\",df[class_label].value_counts())\n",
    "    \n",
    "    #label encode\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if df[i].dtypes == 'object':\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "    #Splitting data into train and test\n",
    "    length = len(df.columns)\n",
    "    X = df.iloc[:,:length-1]\n",
    "    y = df[class_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "    \n",
    "    #Get index    \n",
    "    feature = X.keys().tolist()    \n",
    "    sa_index = feature.index(protected_attribute)\n",
    "    p_Group = 0 \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test,sa_index, p_Group, protected_attribute,majority_group_name,minority_group_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(dataset, X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,majority_group_name,minority_group_name, algorithm, preprocessing_algorithm='', postprocessing_algorithm=''):    \n",
    "    datasetTrain = BinaryLabelDataset(df=pd.concat([X_train, y_train.to_frame()], axis=1), label_names=[y_train.name], protected_attribute_names=[protected_attribute])\n",
    "    datasetTest = BinaryLabelDataset(df=pd.concat([X_test, y_test.to_frame()], axis=1), label_names=[y_test.name], protected_attribute_names=[protected_attribute])\n",
    "    \n",
    "    # preprocessing\n",
    "    if preprocessing_algorithm != '': \n",
    "        if preprocessing_algorithm == 'DIR':\n",
    "            pre_model = DisparateImpactRemover(sensitive_attribute=protected_attribute)\n",
    "        elif preprocessing_algorithm == 'LFR':\n",
    "            privileged_groups = [{protected_attribute: 1.0}]\n",
    "            unprivileged_groups = [{protected_attribute: 0.0}]\n",
    "            pre_model = LFR(unprivileged_groups=unprivileged_groups,privileged_groups=privileged_groups)\n",
    "        dataset_train_transf = pre_model.fit_transform(datasetTrain)\n",
    "        dataset_test_transf = pre_model.transform(datasetTest)\n",
    "\n",
    "        X_train_transf = dataset_train_transf.features\n",
    "        y_train_transf = dataset_train_transf.labels.ravel()\n",
    "        X_test_transf = dataset_test_transf.features\n",
    "        y_test_transf= dataset_test_transf.labels.ravel()\n",
    "\n",
    "        X_train_transf = pd.DataFrame(X_train_transf, columns = X_train.columns)\n",
    "        y_train_transf = pd.Series(y_train_transf, name = y_train.name).astype(int)\n",
    "        X_test_transf = pd.DataFrame(X_test_transf, columns = X_train.columns)\n",
    "        y_test_transf = pd.Series(y_test_transf, name = y_train.name).astype(int)\n",
    "    \n",
    "    # inprocessing\n",
    "    if algorithm == 'DT':\n",
    "        model = tree.DecisionTreeClassifier(random_state=0)  \n",
    "    elif algorithm == 'NB': \n",
    "        model = GaussianNB()\n",
    "    elif algorithm == 'MLP':\n",
    "        model = MLPClassifier(random_state=1, max_iter=300)\n",
    "    elif algorithm == 'kNN':\n",
    "        model = KNeighborsClassifier(n_neighbors=5)\n",
    "    elif algorithm == 'Agar':\n",
    "        clf =  NB = GaussianNB()\n",
    "        model = ExponentiatedGradientReduction(prot_attr=protected_attribute,estimator=clf, constraints = \"EqualizedOdds\")\n",
    "    \n",
    "    if preprocessing_algorithm != '':\n",
    "        model.fit(X_train_transf, y_train_transf)\n",
    "        y_predicts = model.predict(X_test_transf)\n",
    "    else:\n",
    "        model.fit(X_train,y_train)\n",
    "        y_predicts = model.predict(X_test)\n",
    "\n",
    "    # postprocessing\n",
    "    if postprocessing_algorithm != '':\n",
    "        privileged_groups = [{protected_attribute: 1.0}]\n",
    "        unprivileged_groups = [{protected_attribute: 0.0}]\n",
    "        if postprocessing_algorithm == 'EOP':\n",
    "            post_model = EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=42)\n",
    "        if postprocessing_algorithm == 'CEP':\n",
    "            post_model = CalibratedEqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=42)\n",
    "        \n",
    "        y_test_predicts = model.predict(X_test)\n",
    "        y_train_predicts = model.predict(X_train)\n",
    "\n",
    "        X_train_predicts = X_train.copy()\n",
    "        X_test_predicts = X_test.copy()\n",
    "\n",
    "        X_train_predicts[y_train.name] = y_train_predicts\n",
    "        X_test_predicts[y_train.name] = y_test_predicts\n",
    "    \n",
    "        dataset_train_true = BinaryLabelDataset(df=pd.concat([X_train, y_train.to_frame()], axis=1), label_names=[y_train.name], protected_attribute_names=[protected_attribute])\n",
    "        dataset_train_predicts = BinaryLabelDataset(df=X_train_predicts, label_names=[y_train.name], protected_attribute_names=[protected_attribute])\n",
    "        dataset_test_predicts = BinaryLabelDataset(df=X_test_predicts, label_names=[y_test.name], protected_attribute_names=[protected_attribute])\n",
    "\n",
    "        post_model.fit_predict(dataset_true=dataset_train_true, dataset_pred=dataset_train_predicts)\n",
    "        dataset_predicts_transf = post_model.predict(dataset_test_predicts)\n",
    "        data_predicts = dataset_predicts_transf.convert_to_dataframe()[0]\n",
    "        y_predicts = data_predicts[y_test.name].astype(int)\n",
    "\n",
    "    print(\"Statistical parity:\")\n",
    "    print(calculate_performance_statistical_parity(X_test.values, y_test.values, y_predicts, sa_index, p_Group))\n",
    "         \n",
    "    print(\"Equal opportunity\")\n",
    "    print(calculate_performance_equal_opportunity(X_test.values, y_test.values, y_predicts,  sa_index, p_Group))\n",
    "        \n",
    "    print(\"Equalized odds\")\n",
    "    print(calculate_performance_equalized_odds(X_test.values, y_test.values, y_predicts, sa_index, p_Group))\n",
    "         \n",
    "    print(\"Predictive parity\")\n",
    "    print(calculate_performance_predictive_parity(X_test.values, y_test.values, y_predicts,  sa_index, p_Group))\n",
    "        \n",
    "    print(\"Predictive equality\")\n",
    "    print(calculate_performance_predictive_equality(X_test.values, y_test.values, y_predicts,  sa_index, p_Group))\n",
    "        \n",
    "    print(\"Treatment equality\")\n",
    "    print(calculate_performance_treatment_equality(X_test.values, y_test.values, y_predicts,  sa_index, p_Group))\n",
    "        \n",
    "    filename = '{}.{}.abroca.pdf'.format(dataset, preprocessing_algorithm+algorithm)\n",
    "    #make predictions\n",
    "    if postprocessing_algorithm == '':\n",
    "        if preprocessing_algorithm:\n",
    "            X_test['pred_proba'] = model.predict_proba(X_test_transf)[:,1:2]\n",
    "        else:\n",
    "            X_test['pred_proba'] = model.predict_proba(X_test)[:,1:2]\n",
    "        X_test['true_label'] = y_test\n",
    "        df_test = X_test\n",
    "\n",
    "        #Compute Abroca\n",
    "        slice = compute_abroca(df_test, pred_col = 'pred_proba' , label_col = 'true_label', protected_attr_col = protected_attribute,\n",
    "                            majority_protected_attr_val = 1, n_grid = 10000,\n",
    "                            plot_slices = True, majority_group_name=majority_group_name ,minority_group_name=minority_group_name,file_name = filename)\n",
    "        print(\"ABROCA:\",slice)\n",
    "        plt.clf() \n",
    "    plt.clf() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main function\n",
    "def run_eval(dataset, algorithm, preprocessing_algorithm='', postprocessing_algorithm=''):\n",
    "    if dataset == 'credit-approval':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,majority_group_name,minority_group_name = load_credit_approval()\n",
    "        run_experiment(dataset, X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,majority_group_name,minority_group_name, algorithm, preprocessing_algorithm, postprocessing_algorithm)                                        \n",
    "    if dataset == 'credit-card':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,majority_group_name,minority_group_name = load_credit_card()\n",
    "        run_experiment(dataset, X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,majority_group_name,minority_group_name, algorithm, preprocessing_algorithm, postprocessing_algorithm)                                        \n",
    "    if dataset == 'german-credit':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,majority_group_name,minority_group_name = load_german_credit()\n",
    "        run_experiment(dataset, X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,majority_group_name,minority_group_name, algorithm, preprocessing_algorithm, postprocessing_algorithm)                                            \n",
    "    if dataset == 'PAKDD':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,majority_group_name,minority_group_name = load_PAKDD2010()\n",
    "        run_experiment(dataset, X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,majority_group_name,minority_group_name, algorithm, preprocessing_algorithm, postprocessing_algorithm)                                                                \n",
    "    if dataset == 'credit-scoring':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,majority_group_name,minority_group_name = load_credit_scoring()\n",
    "        run_experiment(dataset, X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,majority_group_name,minority_group_name, algorithm, preprocessing_algorithm, postprocessing_algorithm)                                                                        \n",
    "    if dataset == 'application':\n",
    "        X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,majority_group_name,minority_group_name = load_application()\n",
    "        run_experiment(dataset, X_train, X_test, y_train, y_test,sa_index, p_Group,protected_attribute,majority_group_name,minority_group_name, algorithm, preprocessing_algorithm, postprocessing_algorithm)                                                                       "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAKDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='DT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='NB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='kNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='Agar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='DT', preprocessing_algorithm='DIR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='NB', preprocessing_algorithm='DIR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='MLP', preprocessing_algorithm='DIR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='kNN', preprocessing_algorithm='DIR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='DT', preprocessing_algorithm='LFR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='NB', preprocessing_algorithm='LFR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='MLP', preprocessing_algorithm='LFR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='kNN', preprocessing_algorithm='LFR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='DT', postprocessing_algorithm='EOP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='NB', postprocessing_algorithm='EOP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='MLP', postprocessing_algorithm='EOP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='kNN', postprocessing_algorithm='EOP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='DT', postprocessing_algorithm='CEP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='NB', postprocessing_algorithm='CEP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='MLP', postprocessing_algorithm='CEP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval(dataset='PAKDD', algorithm='kNN', postprocessing_algorithm='CEP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
